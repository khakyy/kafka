[2023-12-03 23:07:56,611] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2023-12-03 23:07:56,617] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=E:\KOSA\lib\confluent-7.5.1/logs, -Dlog4j.configuration=file:E:\KOSA\lib\confluent-7.5.1/etc/kafka/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 11.0.17, 11.0.17+10-LTS-269
	jvm.classpath = C:\Program Files\Java\jdk-11.0.17\lib;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\activation-1.1.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\aopalliance-repackaged-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\argparse4j-0.7.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\audience-annotations-0.13.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\commons-cli-1.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\commons-lang3-3.8.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-api-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-basic-auth-extension-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-json-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-mirror-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-mirror-client-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-runtime-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-transforms-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\hk2-api-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\hk2-locator-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\hk2-utils-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-annotations-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-core-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-databind-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-dataformat-csv-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-datatype-jdk8-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-jaxrs-base-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-jaxrs-json-provider-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-module-jaxb-annotations-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-module-scala_2.13-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.activation-api-1.2.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.annotation-api-1.3.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.inject-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.validation-api-2.0.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.ws.rs-api-2.1.6.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.xml.bind-api-2.3.3.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javassist-3.29.2-GA.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.activation-api-1.2.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.annotation-api-1.3.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.servlet-api-3.1.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.ws.rs-api-2.1.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jaxb-api-2.3.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-client-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-common-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-container-servlet-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-container-servlet-core-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-hk2-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-server-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-client-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-continuation-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-http-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-io-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-security-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-server-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-servlet-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-servlets-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-util-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-util-ajax-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jline-3.22.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jopt-simple-5.0.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jose4j-0.9.3.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-clients-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-group-coordinator-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-log4j-appender-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-metadata-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-raft-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-server-common-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-shell-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-storage-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-storage-api-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-examples-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-scala_2.13-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-test-utils-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-tools-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-tools-api-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka_2.13-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\lz4-java-1.8.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\mariadb-java-client-3.1.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\maven-artifact-3.8.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\metrics-core-2.2.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\metrics-core-4.1.12.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-buffer-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-codec-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-common-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-handler-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-resolver-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-classes-epoll-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-native-epoll-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-native-unix-common-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\ojdbc11.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\osgi-resource-locator-1.0.3.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\paranamer-2.8.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\plexus-utils-3.3.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\reflections-0.9.12.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\reload4j-1.2.25.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\rocksdbjni-7.1.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-collection-compat_2.13-2.10.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-java8-compat_2.13-1.0.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-library-2.13.10.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-logging_2.13-3.9.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-reflect-2.13.10.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\slf4j-api-1.7.36.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\slf4j-reload4j-1.7.36.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\snappy-java-1.1.10.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\swagger-annotations-2.2.8.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\trogdor-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\zookeeper-3.6.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\zookeeper-jute-3.6.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\zstd-jni-1.5.5-1.jar
	os.spec = Windows 10, amd64, 10.0
	os.vcpus = 12
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2023-12-03 23:07:56,628] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2023-12-03 23:07:57,848] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@299a06ac (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2023-12-03 23:07:57,849] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,850] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,851] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,851] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,852] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,853] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,853] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,854] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,855] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,855] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,856] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,857] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,857] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,858] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,858] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,859] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,860] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,861] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,861] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,862] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,863] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,863] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,864] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,865] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,867] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,868] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,869] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,869] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,870] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,871] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,872] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,873] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,873] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,874] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,875] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,875] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,876] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,877] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,877] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,878] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,878] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,879] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,880] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,883] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,884] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,884] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,885] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,886] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,887] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,887] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,888] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,889] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,890] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:07:57,951] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,952] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,953] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,954] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,954] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,955] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,956] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,957] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,957] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,958] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,958] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,959] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,959] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,960] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,961] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,961] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,962] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,963] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,963] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,964] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,965] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,965] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,966] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,966] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,967] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,968] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:07:57,968] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:07:57,969] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:07:57,970] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:07:57,971] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:07:57,971] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:07:57,972] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:07:57,972] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:07:57,973] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:07:57,974] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:07:57,974] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,975] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:57,976] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:07:58,033] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [E:KOSAlibconfluentinc-kafka-connect-jdbc-10.7.4lib]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:369)
[2023-12-03 23:07:58,039] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:261)
[2023-12-03 23:07:58,043] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2023-12-03 23:07:58,120] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:378)
[2023-12-03 23:07:58,121] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:07:58,121] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:07:58,122] INFO Kafka startTimeMs: 1701612478120 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:07:58,433] INFO Kafka cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.connect.runtime.WorkerConfig:278)
[2023-12-03 23:07:58,434] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:07:58,439] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:07:58,439] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:07:58,440] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:07:58,565] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:369)
[2023-12-03 23:07:58,576] INFO Logging initialized @2580ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2023-12-03 23:07:58,618] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:111)
[2023-12-03 23:07:58,619] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:182)
[2023-12-03 23:07:58,637] INFO jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 11.0.17+10-LTS-269 (org.eclipse.jetty.server.Server:375)
[2023-12-03 23:07:58,662] INFO Started http_8083@36361ddb{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2023-12-03 23:07:58,662] INFO Started @2666ms (org.eclipse.jetty.server.Server:415)
[2023-12-03 23:07:58,683] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:07:58,684] INFO REST server listening at http://192.168.0.6:8083/, advertising URL http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:202)
[2023-12-03 23:07:58,685] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:07:58,686] INFO REST admin endpoints at http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:205)
[2023-12-03 23:07:58,687] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:07:58,688] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2023-12-03 23:07:58,697] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:369)
[2023-12-03 23:07:58,714] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:07:58,714] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:07:58,715] INFO Kafka startTimeMs: 1701612478714 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:07:58,721] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:369)
[2023-12-03 23:07:58,722] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:369)
[2023-12-03 23:07:58,739] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:07:58,764] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:07:58,765] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:07:58,766] INFO Kafka startTimeMs: 1701612478764 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:07:58,769] INFO Kafka Connect worker initialization took 2155ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2023-12-03 23:07:58,769] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2023-12-03 23:07:58,772] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:209)
[2023-12-03 23:07:58,773] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:359)
[2023-12-03 23:07:58,774] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:206)
[2023-12-03 23:07:58,774] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:264)
[2023-12-03 23:07:58,775] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2023-12-03 23:07:58,776] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2023-12-03 23:07:58,784] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:378)
[2023-12-03 23:07:58,785] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:07:58,786] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:07:58,787] INFO Kafka startTimeMs: 1701612478785 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:07:58,811] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:227)
[2023-12-03 23:07:58,824] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:369)
[2023-12-03 23:07:58,843] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:378)
[2023-12-03 23:07:58,844] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:07:58,845] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:07:58,845] INFO Kafka startTimeMs: 1701612478844 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:07:58,851] INFO [Producer clientId=connect-cluster--offsets] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:07:58,853] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2023-12-03 23:07:58,854] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2023-12-03 23:07:58,855] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2023-12-03 23:07:58,855] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2023-12-03 23:07:58,889] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:378)
[2023-12-03 23:07:58,890] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:07:58,891] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:07:58,891] INFO Kafka startTimeMs: 1701612478890 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:07:58,897] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:07:58,901] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2023-12-03 23:07:58,905] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,905] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,906] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,907] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,907] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,908] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,909] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,909] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,910] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,911] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,911] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,912] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,913] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,913] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,914] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,914] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,915] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,916] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,918] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,918] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,919] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,920] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,921] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,921] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,922] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:58,952] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,953] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,954] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,955] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,956] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,956] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,957] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,958] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,959] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,960] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,961] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,962] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,963] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,964] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,966] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,966] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,967] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,968] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,969] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,970] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,970] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,971] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,972] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,973] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,973] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:58,975] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2023-12-03 23:07:58,975] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2023-12-03 23:07:58,976] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:281)
[2023-12-03 23:07:58,979] INFO Worker started (org.apache.kafka.connect.runtime.Worker:216)
[2023-12-03 23:07:58,979] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2023-12-03 23:07:58,986] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:369)
[2023-12-03 23:07:58,993] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:378)
[2023-12-03 23:07:58,994] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:07:58,995] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:07:58,995] INFO Kafka startTimeMs: 1701612478994 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:07:58,997] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2023-12-03 23:07:58,997] INFO [Producer clientId=connect-cluster--statuses] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:07:59,006] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:378)
[2023-12-03 23:07:59,007] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:07:59,007] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:07:59,008] INFO Kafka startTimeMs: 1701612479007 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:07:59,012] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:07:59,014] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2023-12-03 23:07:59,014] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:59,015] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:59,016] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:59,016] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:59,017] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:59,024] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:59,025] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:59,026] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:59,027] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:59,028] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:59,031] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2023-12-03 23:07:59,032] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2023-12-03 23:07:59,035] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:370)
[2023-12-03 23:07:59,035] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2023-12-03 23:07:59,041] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:369)
[2023-12-03 23:07:59,048] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:378)
[2023-12-03 23:07:59,048] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:07:59,049] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:07:59,050] INFO Kafka startTimeMs: 1701612479048 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:07:59,051] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2023-12-03 23:07:59,051] INFO [Producer clientId=connect-cluster--configs] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:07:59,058] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:378)
[2023-12-03 23:07:59,058] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:07:59,059] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:07:59,060] INFO Kafka startTimeMs: 1701612479058 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:07:59,065] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:07:59,066] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2023-12-03 23:07:59,067] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:07:59,075] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:07:59,118] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2023-12-03 23:07:59,119] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2023-12-03 23:07:59,120] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:394)
[2023-12-03 23:07:59,121] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:364)
[2023-12-03 23:07:59,127] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:07:59,128] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:906)
[2023-12-03 23:07:59,130] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:231)
[2023-12-03 23:07:59,130] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2023-12-03 23:07:59,142] INFO [Worker clientId=connect-1, groupId=connect-cluster] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1072)
[2023-12-03 23:07:59,143] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2023-12-03 23:07:59,146] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=1, memberId='connect-1-be36ae47-091a-4a11-8313-e91784abe54e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:637)
[2023-12-03 23:07:59,166] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=1, memberId='connect-1-be36ae47-091a-4a11-8313-e91784abe54e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:812)
[2023-12-03 23:07:59,167] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-be36ae47-091a-4a11-8313-e91784abe54e', leaderUrl='http://192.168.0.6:8083/', offset=1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2387)
[2023-12-03 23:07:59,168] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1603)
[2023-12-03 23:07:59,169] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 1, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1668)
[2023-12-03 23:07:59,173] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1695)
[2023-12-03 23:07:59,173] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1754)
[2023-12-03 23:07:59,174] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1782)
[2023-12-03 23:07:59,329] INFO Started o.e.j.s.ServletContextHandler@1ba359bd{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2023-12-03 23:07:59,330] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:302)
[2023-12-03 23:07:59,330] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2023-12-03 23:08:39,032] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:702)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:702)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:470)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:390)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2023-12-03 23:08:39,074] INFO 127.0.0.1 - - [03/12/2023:14:08:38 +0000] "POST /connectors HTTP/1.1" 500 2108 "-" "PostmanRuntime/7.35.0" 151 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:09:04,535] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:702)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:702)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:470)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:390)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2023-12-03 23:09:04,540] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:09:04 +0000] "POST /connectors HTTP/1.1" 500 2108 "-" "PostmanRuntime/7.35.0" 10 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:09:11,168] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:702)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:702)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:470)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:390)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2023-12-03 23:09:11,172] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:09:11 +0000] "POST /connectors HTTP/1.1" 500 2108 "-" "PostmanRuntime/7.35.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:09:34,747] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:702)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:702)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:470)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:390)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2023-12-03 23:09:34,751] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:09:34 +0000] "POST /connectors HTTP/1.1" 500 2108 "-" "PostmanRuntime/7.35.0" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:11:54,557] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:702)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:702)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:470)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:390)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2023-12-03 23:11:54,561] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:11:54 +0000] "POST /connectors HTTP/1.1" 500 2108 "-" "PostmanRuntime/7.35.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:12:58,796] INFO [AdminClient clientId=connect-cluster--shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:977)
[2023-12-03 23:14:02,424] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2023-12-03 23:14:02,425] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:348)
[2023-12-03 23:14:02,430] INFO Stopped http_8083@36361ddb{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2023-12-03 23:14:02,431] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2023-12-03 23:14:02,433] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2023-12-03 23:14:02,433] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:803)
[2023-12-03 23:14:02,434] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:766)
[2023-12-03 23:14:02,434] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-be36ae47-091a-4a11-8313-e91784abe54e sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1133)
[2023-12-03 23:14:02,435] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1025)
[2023-12-03 23:14:02,436] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1110)
[2023-12-03 23:14:02,436] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:14:02,437] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:14:02,438] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:14:02,439] INFO App info kafka.connect for connect-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:14:02,440] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2023-12-03 23:14:02,441] INFO [Producer clientId=connect-cluster--statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1310)
[2023-12-03 23:14:02,442] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:14:02,444] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:14:02,444] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:14:02,445] INFO App info kafka.producer for connect-cluster--statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:14:02,446] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2023-12-03 23:14:02,447] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2023-12-03 23:14:02,731] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:14:02,731] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:14:02,733] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:14:02,734] INFO App info kafka.consumer for connect-cluster--statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:14:02,734] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2023-12-03 23:14:02,735] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:399)
[2023-12-03 23:14:02,736] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2023-12-03 23:14:02,736] INFO [Producer clientId=connect-cluster--configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1310)
[2023-12-03 23:14:02,738] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:14:02,738] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:14:02,738] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:14:02,739] INFO App info kafka.producer for connect-cluster--configs unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:14:02,740] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2023-12-03 23:14:02,740] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2023-12-03 23:14:02,827] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:14:02,827] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:14:02,829] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:14:02,830] INFO App info kafka.consumer for connect-cluster--configs unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:14:02,831] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2023-12-03 23:14:02,831] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:405)
[2023-12-03 23:14:02,832] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:223)
[2023-12-03 23:14:02,833] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:293)
[2023-12-03 23:14:02,833] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2023-12-03 23:14:02,834] INFO [Producer clientId=connect-cluster--offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1310)
[2023-12-03 23:14:02,835] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:14:02,835] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:14:02,836] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:14:02,837] INFO App info kafka.producer for connect-cluster--offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:14:02,837] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2023-12-03 23:14:02,838] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2023-12-03 23:14:03,179] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:14:03,179] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:14:03,180] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:14:03,181] INFO App info kafka.consumer for connect-cluster--offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:14:03,181] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2023-12-03 23:14:03,182] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:301)
[2023-12-03 23:14:03,183] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:14:03,183] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:14:03,184] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:14:03,185] INFO App info kafka.connect for 192.168.0.6:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:14:03,185] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:244)
[2023-12-03 23:14:03,186] INFO App info kafka.admin.client for connect-cluster--shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:14:03,187] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:14:03,188] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:14:03,188] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:14:03,189] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:373)
[2023-12-03 23:14:03,190] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:823)
[2023-12-03 23:14:03,190] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2023-12-03 23:14:09,405] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2023-12-03 23:14:09,410] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=E:\KOSA\lib\confluent-7.5.1/logs, -Dlog4j.configuration=file:E:\KOSA\lib\confluent-7.5.1/etc/kafka/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 11.0.17, 11.0.17+10-LTS-269
	jvm.classpath = C:\Program Files\Java\jdk-11.0.17\lib;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\activation-1.1.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\aopalliance-repackaged-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\argparse4j-0.7.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\audience-annotations-0.13.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\commons-cli-1.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\commons-lang3-3.8.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-api-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-basic-auth-extension-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-json-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-mirror-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-mirror-client-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-runtime-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-transforms-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\hk2-api-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\hk2-locator-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\hk2-utils-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-annotations-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-core-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-databind-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-dataformat-csv-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-datatype-jdk8-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-jaxrs-base-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-jaxrs-json-provider-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-module-jaxb-annotations-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-module-scala_2.13-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.activation-api-1.2.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.annotation-api-1.3.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.inject-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.validation-api-2.0.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.ws.rs-api-2.1.6.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.xml.bind-api-2.3.3.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javassist-3.29.2-GA.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.activation-api-1.2.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.annotation-api-1.3.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.servlet-api-3.1.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.ws.rs-api-2.1.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jaxb-api-2.3.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-client-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-common-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-container-servlet-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-container-servlet-core-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-hk2-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-server-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-client-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-continuation-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-http-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-io-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-security-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-server-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-servlet-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-servlets-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-util-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-util-ajax-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jline-3.22.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jopt-simple-5.0.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jose4j-0.9.3.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-clients-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-group-coordinator-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-log4j-appender-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-metadata-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-raft-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-server-common-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-shell-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-storage-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-storage-api-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-examples-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-scala_2.13-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-test-utils-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-tools-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-tools-api-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka_2.13-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\lz4-java-1.8.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\mariadb-java-client-3.1.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\maven-artifact-3.8.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\metrics-core-2.2.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\metrics-core-4.1.12.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-buffer-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-codec-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-common-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-handler-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-resolver-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-classes-epoll-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-native-epoll-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-native-unix-common-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\ojdbc11.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\osgi-resource-locator-1.0.3.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\paranamer-2.8.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\plexus-utils-3.3.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\reflections-0.9.12.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\reload4j-1.2.25.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\rocksdbjni-7.1.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-collection-compat_2.13-2.10.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-java8-compat_2.13-1.0.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-library-2.13.10.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-logging_2.13-3.9.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-reflect-2.13.10.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\slf4j-api-1.7.36.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\slf4j-reload4j-1.7.36.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\snappy-java-1.1.10.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\swagger-annotations-2.2.8.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\trogdor-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\zookeeper-3.6.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\zookeeper-jute-3.6.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\zstd-jni-1.5.5-1.jar
	os.spec = Windows 10, amd64, 10.0
	os.vcpus = 12
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2023-12-03 23:14:09,417] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2023-12-03 23:14:10,545] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@299a06ac (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2023-12-03 23:14:10,545] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,547] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,547] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,548] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,548] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,549] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,550] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,550] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,551] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,551] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,552] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,553] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,553] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,554] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,555] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,555] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,556] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,557] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,557] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,558] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,559] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,560] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,560] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,561] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,562] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,562] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,563] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,564] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,566] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,566] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,567] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,567] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,568] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,569] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,569] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,570] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,570] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,571] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,571] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,572] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,573] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,573] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,574] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,574] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,575] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,575] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,576] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,577] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,577] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,578] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,578] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,579] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,580] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:14:10,641] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,642] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,643] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,643] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,644] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,645] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,646] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,646] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,647] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,647] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,648] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,648] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,649] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,650] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,650] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,651] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,652] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,652] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,653] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,653] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,654] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,654] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,655] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,655] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,656] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,657] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:14:10,658] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:14:10,658] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:14:10,659] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:14:10,659] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:14:10,660] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:14:10,662] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:14:10,663] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:14:10,663] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:14:10,664] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:14:10,665] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,665] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,666] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:14:10,726] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [E:KOSAlibconfluentinc-kafka-connect-jdbc-10.7.4lib]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:369)
[2023-12-03 23:14:10,731] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:261)
[2023-12-03 23:14:10,734] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2023-12-03 23:14:10,801] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:378)
[2023-12-03 23:14:10,802] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:14:10,802] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:14:10,803] INFO Kafka startTimeMs: 1701612850801 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:14:11,112] INFO Kafka cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.connect.runtime.WorkerConfig:278)
[2023-12-03 23:14:11,113] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:14:11,118] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:14:11,118] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:14:11,119] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:14:11,256] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:369)
[2023-12-03 23:14:11,268] INFO Logging initialized @2448ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2023-12-03 23:14:11,311] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:111)
[2023-12-03 23:14:11,312] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:182)
[2023-12-03 23:14:11,335] INFO jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 11.0.17+10-LTS-269 (org.eclipse.jetty.server.Server:375)
[2023-12-03 23:14:11,360] INFO Started http_8083@30a7c98f{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2023-12-03 23:14:11,361] INFO Started @2541ms (org.eclipse.jetty.server.Server:415)
[2023-12-03 23:14:11,384] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:14:11,385] INFO REST server listening at http://192.168.0.6:8083/, advertising URL http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:202)
[2023-12-03 23:14:11,386] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:14:11,387] INFO REST admin endpoints at http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:205)
[2023-12-03 23:14:11,387] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:14:11,388] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2023-12-03 23:14:11,395] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:369)
[2023-12-03 23:14:11,408] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:14:11,409] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:14:11,410] INFO Kafka startTimeMs: 1701612851408 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:14:11,415] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:369)
[2023-12-03 23:14:11,416] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:369)
[2023-12-03 23:14:11,433] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:14:11,458] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:14:11,459] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:14:11,464] INFO Kafka startTimeMs: 1701612851458 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:14:11,468] INFO Kafka Connect worker initialization took 2061ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2023-12-03 23:14:11,468] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2023-12-03 23:14:11,471] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:209)
[2023-12-03 23:14:11,471] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:359)
[2023-12-03 23:14:11,472] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:206)
[2023-12-03 23:14:11,472] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:264)
[2023-12-03 23:14:11,472] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2023-12-03 23:14:11,474] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2023-12-03 23:14:11,481] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:378)
[2023-12-03 23:14:11,482] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:14:11,482] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:14:11,483] INFO Kafka startTimeMs: 1701612851482 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:14:11,514] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:227)
[2023-12-03 23:14:11,516] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:369)
[2023-12-03 23:14:11,537] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:378)
[2023-12-03 23:14:11,537] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:14:11,538] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:14:11,538] INFO Kafka startTimeMs: 1701612851537 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:14:11,545] INFO [Producer clientId=connect-cluster--offsets] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:14:11,547] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2023-12-03 23:14:11,557] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2023-12-03 23:14:11,558] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2023-12-03 23:14:11,559] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2023-12-03 23:14:11,578] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:378)
[2023-12-03 23:14:11,579] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:14:11,580] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:14:11,580] INFO Kafka startTimeMs: 1701612851579 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:14:11,586] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:14:11,589] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2023-12-03 23:14:11,592] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,593] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,593] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,594] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,595] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,596] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,596] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,597] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,597] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,598] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,599] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,599] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,600] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,600] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,601] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,602] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,602] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,603] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,605] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,606] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,607] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,607] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,608] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,609] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,609] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,634] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,635] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,637] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,638] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,638] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,639] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,640] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,641] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,641] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,642] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,643] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,644] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,644] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,645] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,646] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,647] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,647] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,648] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,649] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,650] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,651] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,653] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,654] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,655] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,655] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,656] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2023-12-03 23:14:11,657] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2023-12-03 23:14:11,657] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:281)
[2023-12-03 23:14:11,659] INFO Worker started (org.apache.kafka.connect.runtime.Worker:216)
[2023-12-03 23:14:11,660] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2023-12-03 23:14:11,667] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:369)
[2023-12-03 23:14:11,678] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:378)
[2023-12-03 23:14:11,679] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:14:11,680] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:14:11,680] INFO Kafka startTimeMs: 1701612851679 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:14:11,681] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2023-12-03 23:14:11,682] INFO [Producer clientId=connect-cluster--statuses] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:14:11,690] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:378)
[2023-12-03 23:14:11,691] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:14:11,692] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:14:11,692] INFO Kafka startTimeMs: 1701612851691 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:14:11,696] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:14:11,697] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2023-12-03 23:14:11,698] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,698] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,699] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,701] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,702] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,711] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,712] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,712] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,714] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,714] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,716] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2023-12-03 23:14:11,719] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2023-12-03 23:14:11,722] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:370)
[2023-12-03 23:14:11,722] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2023-12-03 23:14:11,728] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:369)
[2023-12-03 23:14:11,735] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:378)
[2023-12-03 23:14:11,736] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:14:11,736] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:14:11,737] INFO Kafka startTimeMs: 1701612851736 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:14:11,738] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2023-12-03 23:14:11,738] INFO [Producer clientId=connect-cluster--configs] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:14:11,745] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:378)
[2023-12-03 23:14:11,746] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:14:11,747] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:14:11,749] INFO Kafka startTimeMs: 1701612851746 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:14:11,753] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:14:11,754] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2023-12-03 23:14:11,755] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:14:11,761] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:14:11,799] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2023-12-03 23:14:11,800] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2023-12-03 23:14:11,801] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:394)
[2023-12-03 23:14:11,802] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:364)
[2023-12-03 23:14:11,809] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:14:11,810] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:906)
[2023-12-03 23:14:11,812] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:231)
[2023-12-03 23:14:11,812] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2023-12-03 23:14:11,820] INFO [Worker clientId=connect-1, groupId=connect-cluster] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1072)
[2023-12-03 23:14:11,821] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2023-12-03 23:14:11,825] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=3, memberId='connect-1-7e581913-37c3-4eb0-8e88-475eff312990', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:637)
[2023-12-03 23:14:11,839] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=3, memberId='connect-1-7e581913-37c3-4eb0-8e88-475eff312990', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:812)
[2023-12-03 23:14:11,840] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 3 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-7e581913-37c3-4eb0-8e88-475eff312990', leaderUrl='http://192.168.0.6:8083/', offset=1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2387)
[2023-12-03 23:14:11,841] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1603)
[2023-12-03 23:14:11,841] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 1, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1668)
[2023-12-03 23:14:11,845] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1695)
[2023-12-03 23:14:11,846] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1754)
[2023-12-03 23:14:11,846] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1782)
[2023-12-03 23:14:12,024] INFO Started o.e.j.s.ServletContextHandler@4110765e{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2023-12-03 23:14:12,025] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:302)
[2023-12-03 23:14:12,025] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2023-12-03 23:14:20,416] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:702)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:702)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:470)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:390)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2023-12-03 23:14:20,458] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:14:20 +0000] "POST /connectors HTTP/1.1" 500 2108 "-" "PostmanRuntime/7.35.0" 135 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:17:12,639] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:702)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:702)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:470)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:390)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2023-12-03 23:17:12,644] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:17:12 +0000] "POST /connectors HTTP/1.1" 500 2108 "-" "PostmanRuntime/7.35.0" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:17:51,270] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:702)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:702)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:470)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:390)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2023-12-03 23:17:51,274] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:17:51 +0000] "POST /connectors HTTP/1.1" 500 2108 "-" "PostmanRuntime/7.35.0" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:18:05,781] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:18:05 +0000] "GET /connector-plugins HTTP/1.1" 200 320 "-" "PostmanRuntime/7.35.0" 12 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:19:09,090] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:702)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:702)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:470)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:390)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2023-12-03 23:19:09,093] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:19:09 +0000] "POST /connectors HTTP/1.1" 500 2108 "-" "PostmanRuntime/7.35.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:19:11,494] INFO [AdminClient clientId=connect-cluster--shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:977)
[2023-12-03 23:19:18,749] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:19:18 +0000] "GET /connectors-list HTTP/1.1" 404 49 "-" "PostmanRuntime/7.35.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:19:26,882] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:19:26 +0000] "GET /connectors-list HTTP/1.1" 404 49 "-" "PostmanRuntime/7.35.0" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:19:32,970] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:19:32 +0000] "GET /connectors-plugins HTTP/1.1" 404 49 "-" "PostmanRuntime/7.35.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:19:41,032] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:19:41 +0000] "GET /connector-plugins HTTP/1.1" 200 320 "-" "PostmanRuntime/7.35.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:19:44,288] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2023-12-03 23:19:44,288] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:348)
[2023-12-03 23:19:44,293] INFO Stopped http_8083@30a7c98f{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2023-12-03 23:19:44,294] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2023-12-03 23:19:44,295] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2023-12-03 23:19:44,296] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:803)
[2023-12-03 23:19:44,296] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:766)
[2023-12-03 23:19:44,297] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-7e581913-37c3-4eb0-8e88-475eff312990 sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1133)
[2023-12-03 23:19:44,298] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1025)
[2023-12-03 23:19:44,299] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1110)
[2023-12-03 23:19:44,300] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:19:44,301] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:19:44,302] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:19:44,303] INFO App info kafka.connect for connect-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:19:44,304] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2023-12-03 23:19:44,305] INFO [Producer clientId=connect-cluster--statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1310)
[2023-12-03 23:19:44,306] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:19:44,306] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:19:44,307] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:19:44,308] INFO App info kafka.producer for connect-cluster--statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:19:44,309] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2023-12-03 23:19:44,309] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2023-12-03 23:19:44,652] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:19:44,652] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:19:44,653] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:19:44,655] INFO App info kafka.consumer for connect-cluster--statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:19:44,655] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2023-12-03 23:19:44,655] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:399)
[2023-12-03 23:19:44,656] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2023-12-03 23:19:44,657] INFO [Producer clientId=connect-cluster--configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1310)
[2023-12-03 23:19:44,658] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:19:44,658] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:19:44,659] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:19:44,660] INFO App info kafka.producer for connect-cluster--configs unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:19:44,660] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2023-12-03 23:19:44,661] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2023-12-03 23:19:44,731] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:19:44,732] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:19:44,733] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:19:44,734] INFO App info kafka.consumer for connect-cluster--configs unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:19:44,734] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2023-12-03 23:19:44,735] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:405)
[2023-12-03 23:19:44,735] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:223)
[2023-12-03 23:19:44,737] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:293)
[2023-12-03 23:19:44,737] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2023-12-03 23:19:44,738] INFO [Producer clientId=connect-cluster--offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1310)
[2023-12-03 23:19:44,739] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:19:44,739] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:19:44,740] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:19:44,741] INFO App info kafka.producer for connect-cluster--offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:19:44,741] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2023-12-03 23:19:44,742] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2023-12-03 23:19:45,115] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:19:45,116] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:19:45,117] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:19:45,118] INFO App info kafka.consumer for connect-cluster--offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:19:45,118] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2023-12-03 23:19:45,119] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:301)
[2023-12-03 23:19:45,119] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:19:45,120] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:19:45,120] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:19:45,121] INFO App info kafka.connect for 192.168.0.6:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:19:45,122] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:244)
[2023-12-03 23:19:45,123] INFO App info kafka.admin.client for connect-cluster--shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:19:45,124] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:19:45,124] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:19:45,125] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:19:45,125] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:373)
[2023-12-03 23:19:45,126] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:823)
[2023-12-03 23:19:45,127] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2023-12-03 23:19:48,804] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2023-12-03 23:19:48,809] INFO WorkerInfo values: 
	jvm.args = -Xmx256M, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=E:\KOSA\lib\confluent-7.5.1/logs, -Dlog4j.configuration=file:E:\KOSA\lib\confluent-7.5.1/etc/kafka/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 11.0.17, 11.0.17+10-LTS-269
	jvm.classpath = C:\Program Files\Java\jdk-11.0.17\lib;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\activation-1.1.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\aopalliance-repackaged-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\argparse4j-0.7.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\audience-annotations-0.13.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\commons-cli-1.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\commons-lang3-3.8.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-api-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-basic-auth-extension-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-json-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-mirror-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-mirror-client-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-runtime-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\connect-transforms-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\hk2-api-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\hk2-locator-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\hk2-utils-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-annotations-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-core-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-databind-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-dataformat-csv-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-datatype-jdk8-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-jaxrs-base-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-jaxrs-json-provider-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-module-jaxb-annotations-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jackson-module-scala_2.13-2.13.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.activation-api-1.2.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.annotation-api-1.3.5.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.inject-2.6.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.validation-api-2.0.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.ws.rs-api-2.1.6.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jakarta.xml.bind-api-2.3.3.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javassist-3.29.2-GA.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.activation-api-1.2.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.annotation-api-1.3.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.servlet-api-3.1.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\javax.ws.rs-api-2.1.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jaxb-api-2.3.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-client-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-common-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-container-servlet-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-container-servlet-core-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-hk2-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jersey-server-2.39.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-client-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-continuation-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-http-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-io-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-security-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-server-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-servlet-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-servlets-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-util-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jetty-util-ajax-9.4.51.v20230217.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jline-3.22.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jopt-simple-5.0.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\jose4j-0.9.3.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-clients-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-group-coordinator-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-log4j-appender-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-metadata-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-raft-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-server-common-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-shell-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-storage-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-storage-api-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-examples-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-scala_2.13-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-streams-test-utils-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-tools-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka-tools-api-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\kafka_2.13-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\lz4-java-1.8.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\mariadb-java-client-3.1.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\maven-artifact-3.8.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\metrics-core-2.2.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\metrics-core-4.1.12.1.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-buffer-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-codec-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-common-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-handler-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-resolver-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-classes-epoll-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-native-epoll-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\netty-transport-native-unix-common-4.1.96.Final.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\ojdbc11.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\osgi-resource-locator-1.0.3.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\paranamer-2.8.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\plexus-utils-3.3.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\reflections-0.9.12.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\reload4j-1.2.25.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\rocksdbjni-7.1.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-collection-compat_2.13-2.10.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-java8-compat_2.13-1.0.2.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-library-2.13.10.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-logging_2.13-3.9.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\scala-reflect-2.13.10.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\slf4j-api-1.7.36.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\slf4j-reload4j-1.7.36.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\snappy-java-1.1.10.0.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\swagger-annotations-2.2.8.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\trogdor-7.5.1-ccs.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\zookeeper-3.6.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\zookeeper-jute-3.6.4.jar;E:\KOSA\lib\confluent-7.5.1\share\java\kafka\zstd-jni-1.5.5-1.jar
	os.spec = Windows 10, amd64, 10.0
	os.vcpus = 12
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2023-12-03 23:19:48,818] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2023-12-03 23:19:49,913] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@299a06ac (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2023-12-03 23:19:49,913] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,914] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,915] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,915] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,916] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,917] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,917] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,918] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,918] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,919] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,919] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,920] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,921] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,921] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,922] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,923] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,923] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,924] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,924] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,925] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,926] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,928] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,928] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,929] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,929] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,930] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,931] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,931] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,932] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,933] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,933] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,934] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,934] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,935] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,936] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,936] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,937] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,938] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,938] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,939] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,939] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,940] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,941] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,941] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,942] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,944] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,945] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,945] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,946] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,946] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,947] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,947] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:49,948] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2023-12-03 23:19:50,010] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,010] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,011] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,012] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,013] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,013] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,014] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,014] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,015] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,016] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,016] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,017] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,017] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,018] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,019] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,019] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,020] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,020] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,021] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,021] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,022] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,024] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,025] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,025] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,026] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,027] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:19:50,027] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:19:50,028] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:19:50,028] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:19:50,029] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:19:50,029] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:19:50,030] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:19:50,030] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:19:50,031] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:19:50,031] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2023-12-03 23:19:50,032] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,033] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,033] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2023-12-03 23:19:50,084] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [E:KOSAlibconfluentinc-kafka-connect-jdbc-10.7.4lib]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:369)
[2023-12-03 23:19:50,089] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:261)
[2023-12-03 23:19:50,093] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2023-12-03 23:19:50,166] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:378)
[2023-12-03 23:19:50,167] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:19:50,168] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:19:50,169] INFO Kafka startTimeMs: 1701613190167 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:19:50,482] INFO Kafka cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.connect.runtime.WorkerConfig:278)
[2023-12-03 23:19:50,482] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-03 23:19:50,488] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-03 23:19:50,488] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-03 23:19:50,489] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-03 23:19:50,612] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:369)
[2023-12-03 23:19:50,623] INFO Logging initialized @2400ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2023-12-03 23:19:50,664] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:111)
[2023-12-03 23:19:50,665] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:182)
[2023-12-03 23:19:50,682] INFO jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 11.0.17+10-LTS-269 (org.eclipse.jetty.server.Server:375)
[2023-12-03 23:19:50,707] INFO Started http_8083@b2f4ece{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2023-12-03 23:19:50,707] INFO Started @2485ms (org.eclipse.jetty.server.Server:415)
[2023-12-03 23:19:50,728] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:19:50,728] INFO REST server listening at http://192.168.0.6:8083/, advertising URL http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:202)
[2023-12-03 23:19:50,729] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:19:50,730] INFO REST admin endpoints at http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:205)
[2023-12-03 23:19:50,730] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:19:50,732] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2023-12-03 23:19:50,738] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:369)
[2023-12-03 23:19:50,752] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:19:50,752] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:19:50,753] INFO Kafka startTimeMs: 1701613190752 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:19:50,760] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:369)
[2023-12-03 23:19:50,760] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:369)
[2023-12-03 23:19:50,780] INFO Advertised URI: http://192.168.0.6:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:394)
[2023-12-03 23:19:50,805] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:19:50,805] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:19:50,806] INFO Kafka startTimeMs: 1701613190805 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:19:50,810] INFO Kafka Connect worker initialization took 2003ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2023-12-03 23:19:50,811] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2023-12-03 23:19:50,813] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:209)
[2023-12-03 23:19:50,813] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:359)
[2023-12-03 23:19:50,814] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:206)
[2023-12-03 23:19:50,814] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:264)
[2023-12-03 23:19:50,815] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2023-12-03 23:19:50,816] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:369)
[2023-12-03 23:19:50,823] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:378)
[2023-12-03 23:19:50,824] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:19:50,824] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:19:50,825] INFO Kafka startTimeMs: 1701613190824 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:19:50,850] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:227)
[2023-12-03 23:19:50,853] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:369)
[2023-12-03 23:19:50,872] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:378)
[2023-12-03 23:19:50,873] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:19:50,873] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:19:50,874] INFO Kafka startTimeMs: 1701613190873 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:19:50,880] INFO [Producer clientId=connect-cluster--offsets] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:19:50,882] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2023-12-03 23:19:50,892] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2023-12-03 23:19:50,893] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2023-12-03 23:19:50,894] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2023-12-03 23:19:50,918] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:378)
[2023-12-03 23:19:50,919] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:19:50,920] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:19:50,921] INFO Kafka startTimeMs: 1701613190919 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:19:50,927] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:19:50,930] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2023-12-03 23:19:50,934] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,935] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,935] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,936] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,937] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,937] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,938] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,939] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,939] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,940] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,940] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,941] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,942] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,943] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,943] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,944] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,945] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,946] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,946] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,947] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,948] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,948] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,949] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,950] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,952] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:50,975] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,976] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,976] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,977] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,978] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,979] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,980] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,980] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,981] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,982] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,984] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,985] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,986] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,986] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,987] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,988] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,989] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,989] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,990] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,991] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,992] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,993] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,993] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,994] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,995] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:50,996] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2023-12-03 23:19:50,996] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2023-12-03 23:19:50,997] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:281)
[2023-12-03 23:19:50,999] INFO Worker started (org.apache.kafka.connect.runtime.Worker:216)
[2023-12-03 23:19:51,000] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2023-12-03 23:19:51,006] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:369)
[2023-12-03 23:19:51,013] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:378)
[2023-12-03 23:19:51,014] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:19:51,017] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:19:51,017] INFO [Producer clientId=connect-cluster--statuses] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:19:51,018] INFO Kafka startTimeMs: 1701613191014 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:19:51,020] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2023-12-03 23:19:51,028] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:378)
[2023-12-03 23:19:51,029] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:19:51,030] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:19:51,032] INFO Kafka startTimeMs: 1701613191029 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:19:51,037] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:19:51,037] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2023-12-03 23:19:51,038] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:51,039] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:51,039] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:51,040] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:51,041] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:51,050] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:51,050] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:51,051] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:51,052] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:51,053] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:51,055] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2023-12-03 23:19:51,055] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2023-12-03 23:19:51,059] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:370)
[2023-12-03 23:19:51,059] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2023-12-03 23:19:51,066] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:369)
[2023-12-03 23:19:51,074] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:378)
[2023-12-03 23:19:51,074] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:19:51,076] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:19:51,076] INFO Kafka startTimeMs: 1701613191074 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:19:51,078] INFO [Producer clientId=connect-cluster--configs] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:19:51,078] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:369)
[2023-12-03 23:19:51,087] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:378)
[2023-12-03 23:19:51,088] INFO Kafka version: 7.5.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-03 23:19:51,089] INFO Kafka commitId: 18394206009bb2f31244031f70fdb5e5826e2408 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-03 23:19:51,089] INFO Kafka startTimeMs: 1701613191088 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-03 23:19:51,093] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:19:51,097] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2023-12-03 23:19:51,097] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2023-12-03 23:19:51,105] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2023-12-03 23:19:51,149] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2023-12-03 23:19:51,150] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2023-12-03 23:19:51,151] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:394)
[2023-12-03 23:19:51,152] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:364)
[2023-12-03 23:19:51,159] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: vkl-PVllQRuzOPSUL2ifjw (org.apache.kafka.clients.Metadata:287)
[2023-12-03 23:19:51,160] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:906)
[2023-12-03 23:19:51,163] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:231)
[2023-12-03 23:19:51,163] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2023-12-03 23:19:51,171] INFO [Worker clientId=connect-1, groupId=connect-cluster] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1072)
[2023-12-03 23:19:51,172] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2023-12-03 23:19:51,362] INFO Started o.e.j.s.ServletContextHandler@644ded04{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2023-12-03 23:19:51,362] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:302)
[2023-12-03 23:19:51,363] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2023-12-03 23:19:52,553] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=4, memberId='connect-1-33d3f595-d661-4c2b-a900-a7500cb2c0c5', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:637)
[2023-12-03 23:19:52,567] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=4, memberId='connect-1-33d3f595-d661-4c2b-a900-a7500cb2c0c5', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:812)
[2023-12-03 23:19:52,568] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 4 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-33d3f595-d661-4c2b-a900-a7500cb2c0c5', leaderUrl='http://192.168.0.6:8083/', offset=1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2387)
[2023-12-03 23:19:52,569] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1603)
[2023-12-03 23:19:52,569] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 1, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1668)
[2023-12-03 23:19:52,572] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1695)
[2023-12-03 23:19:52,572] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1754)
[2023-12-03 23:19:52,573] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1782)
[2023-12-03 23:19:54,530] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:19:54 +0000] "GET /connector-plugins HTTP/1.1" 200 320 "-" "PostmanRuntime/7.35.0" 98 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:19:55,411] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:19:55 +0000] "GET /connector-plugins HTTP/1.1" 200 320 "-" "PostmanRuntime/7.35.0" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:24:06,650] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:702)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:702)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:470)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:390)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2023-12-03 23:24:06,661] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:24:06 +0000] "POST /connectors HTTP/1.1" 500 2108 "-" "PostmanRuntime/7.35.0" 59 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2023-12-03 23:24:50,845] INFO [AdminClient clientId=connect-cluster--shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:977)
[2023-12-03 23:25:51,035] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=sink, typeName='sink', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.1-ccs', encodedVersion=7.5.1-ccs, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$6(AbstractHerder.java:702)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:702)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:470)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:390)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2023-12-03 23:25:51,038] INFO [0:0:0:0:0:0:0:1] - - [03/12/2023:14:25:51 +0000] "POST /connectors HTTP/1.1" 500 2108 "-" "PostmanRuntime/7.35.0" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
